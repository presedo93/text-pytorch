{"cells":[{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","import torch\n","import torchtext\n","\n","from torchtext import data\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Hyperparameters\n","VOCAB_SIZE = 10000\n","BATCH_SIZE = 16\n","EMBED_DIM = 32\n","NUM_CLASS = 4\n","N_EPOCHS = 5\n","NGRAMS = 2"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["train = pd.read_csv('./data/train.csv')\n","train.head()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["LABEL = data.Field(sequential = False, use_vocab = False)\n","TITLE = data.Field(tokenize = \"spacy\", include_lengths = True)\n","DESCS = data.Field(tokenize = \"spacy\", include_lengths = True)\n","\n","fields = [\n","    (None, None),\n","    ('label', LABEL),\n","    ('title', TITLE),\n","    ('descs', DESCS)\n","]\n","\n","train_ds, test_ds = data.TabularDataset.splits(\n","    path = './data',\n","    train = 'train.csv',\n","    test = 'test.csv',\n","    format = 'csv',\n","    fields = fields,\n","    skip_header = True\n",")\n","\n","train_ds, valid_ds = train_ds.split()"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["LABEL.build_vocab(train_ds, max_size = VOCAB_SIZE)\n","TITLE.build_vocab(train_ds, max_size = VOCAB_SIZE)\n","DESCS.build_vocab(train_ds, max_size = VOCAB_SIZE)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["train_it, valid_it, test_it = data.BucketIterator.splits(\n","  (train_ds, valid_ds, test_ds),\n","    sort_key = lambda x: len(x.descs),\n","    sort = True,\n","    batch_size = BATCH_SIZE,\n","    device = device\n",")"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["# Define the model\n","import torch.nn as nn\n","import torch.nn.functional as f\n","\n","class TextSentiment(nn.Module):\n","    def __init__(self, vocab_size, embed_dim, num_class):\n","        super().__init__()\n","        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=True)\n","        self.fc = nn.Linear(embed_dim, num_class)\n","        self.init_weights()\n","        \n","    def init_weights(self):\n","        initrange = 0.5\n","        self.embedding.weight.data.uniform_(-initrange, initrange)\n","        self.fc.weight.data.uniform_(-initrange, initrange)\n","        self.fc.bias.data.zero_()\n","        \n","    def forward(self, text):\n","        embedded = self.embedding(text)\n","        return self.fc(embedded)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["def train_func(sub_train_):\n","\n","    # Train the model\n","    train_loss = 0\n","    train_acc = 0\n","    \n","    for i, d in enumerate(train_it):\n","        optimizer.zero_grad()\n","        output = model(d.descs[0].T)\n","        loss = criterion(output, d.label)\n","        train_loss += loss.item()\n","        loss.backward()\n","        optimizer.step()\n","        train_acc += (output.argmax(1) == d.label).sum().item()\n","\n","    # Adjust the learning rate\n","    scheduler.step()\n","\n","    return train_loss / len(train_it), train_acc / len(train_it)\n","\n","def test(test_it):\n","    loss = 0\n","    acc = 0\n","\n","    for t in test_it:\n","        with torch.no_grad():\n","            output = model(t.descs[0].T)\n","            loss = criterion(output, t.label)\n","            loss += loss.item()\n","            acc += (output.argmax(1) == t.label).sum().item()\n","\n","    return loss / len(test_it), acc / len(test_it)"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["import time\n","\n","min_valid_loss = float('inf')\n","\n","model = TextSentiment(VOCAB_SIZE, EMBED_DIM, NUM_CLASS).to(device)\n","criterion = torch.nn.CrossEntropyLoss().to(device)\n","optimizer = torch.optim.SGD(model.parameters(), lr = 1e-2)\n","scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma = 0.9)\n","\n","for epoch in range(N_EPOCHS):\n","    start_time = time.time()\n","    train_loss, train_acc = train_func(train_it)\n","    valid_loss, valid_acc = test(valid_it)\n","    \n","    secs = int(time.time() - start_time)\n","    mins = secs / 60\n","    secs = secs % 60\n","    \n","    print('Epoch: %d' %(epoch + 1), \" | time in %d minutes, %d seconds\" %(mins, secs))\n","    print(f'\\tLoss: {train_loss:.4f}(train)\\t|\\tAcc: {train_acc * 100:.1f}%(train)')\n","    print(f'\\tLoss: {valid_loss:.4f}(valid)\\t|\\tAcc: {valid_acc * 100:.1f}%(valid)')"],"execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":["print('Checking the results of test dataset...')\n","test_loss, test_acc = test(test_it)\n","print(f'\\tLoss: {test_loss:.4f}(test)\\t|\\tAcc: {test_acc * 100:.1f}%(test)')"],"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}